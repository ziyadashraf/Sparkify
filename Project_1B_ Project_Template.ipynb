{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ziyadashraf/Documents/Data Engineering with AWS/Course 1/Project\n"
     ]
    }
   ],
   "source": [
    "# checking current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Getting current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Creating a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# joining the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "#\n",
    "#print(len(full_data_rows_list))\n",
    "#\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# checking the number of rows in my csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Cassandra code in the cells below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    session = cluster.connect()\n",
    "    \n",
    "except Exception as e:\n",
    "    print (e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS sparkify\n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1}\n",
    "    \"\"\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparkify wants to know the following:\n",
    "\n",
    "### 1. The artist, song title and song's length in the music app history that was heard during the Session ID: 338, and Item In Session: 4\n",
    "\n",
    "\n",
    "### 2. Name of artist, song (sorted by Item in Session) and user (first and last name) for User ID: 10  and Session ID: 182\n",
    "    \n",
    "\n",
    "### 3. Every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: The artist, song title and song's length in the music app history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Created a table with the columns Artist Name, Song Name, Song Length, Session ID, Item in Session because Sparkify wants to know The artist, song title and song's length in a certain Session ID and Item in Session.\n",
    "\n",
    "-Chose Session ID and Item in Session as the composite key to avoid ALLOW FILTERING and to be able to put them in my WHERE clause without any problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CREATING TABLE artist_songs_length\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS artist_songs_length \"\n",
    "query = query + \"(session_id int, item_in_session int, artist_name text, song text, song_length float, PRIMARY KEY (session_id, item_in_session))\"\n",
    "try:\n",
    "    session.execute (query)\n",
    "except Exception as e:\n",
    "    print (e)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting up csv file\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) \n",
    "    \n",
    "    for line in csvreader:\n",
    "#Assigning the INSERT statements \n",
    "        query = \"INSERT INTO artist_songs_length (session_id, item_in_session, artist_name, song, song_length) \"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        #Assigning which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECT Statement for Query 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-This query is just getting the data Sparkify wanted and listing them based on the specific Session ID and Item in Session given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Artist Name                             Song  Song length  Session ID  \\\n",
      "0   Faithless  Music Matters (Mark Knight Dub)   495.307312         338   \n",
      "\n",
      "   Item in Session ID  \n",
      "0                   4  \n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist_name, song, song_length, session_id, item_in_session FROM artist_songs_length \\\n",
    "        WHERE session_id = 338 AND item_in_session = 4\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(rows, columns=['Artist Name', 'Song', 'Song length', 'Session ID', 'Item in Session ID'])\n",
    "\n",
    "print (df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2:  Name of artist, song (sorted by Item in Session) and user (first and last name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Created a table with the columns Artist Name, Song Name, user first and last names, User ID, Item in Session ID and Session ID because Sparkify wants to know The artist of each song, the song title sorted with respect to Item in Session ID, the user name based on a given session ID and user ID.\n",
    "\n",
    "-Chose User ID and Session ID as the partition keys to avoid ALLOW FILTERING and to be able to put them in my WHERE clause without any problems. Added the clustering column Item in Session ID to the primary key to be able to sort my songs with respect to the Item in Session ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CREATING TABLE user_songs\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_songs \"\n",
    "query = query + \"(user_id int, session_id int, item_in_session int, artist_name text, song text,  first_name text, last_name text,  PRIMARY KEY ((user_id, session_id), item_in_session))\"\n",
    "\n",
    "\n",
    "try:\n",
    "    session.execute (query)\n",
    "except Exception as e:\n",
    "    print (e)        \n",
    "\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting up csv file\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) \n",
    "    \n",
    "    for line in csvreader:\n",
    "    #Assign the INSERT statements \n",
    "        query = \"INSERT INTO user_songs (user_id, session_id, item_in_session, artist_name, song,  first_name, last_name )\"\n",
    "    \n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        \n",
    "        #Assigning which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECT Statement for Query 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-This query is just getting the data Sparkify wanted and listing them based on the specific Session ID and User ID given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User ID  Session ID  Item in Session        Artist Name  \\\n",
      "0       10         182                0   Down To The Bone   \n",
      "1       10         182                1       Three Drives   \n",
      "2       10         182                2  Sebastien Tellier   \n",
      "3       10         182                3      Lonnie Gordon   \n",
      "\n",
      "                                                Song First Name Last Name  \n",
      "0                                 Keep On Keepin' On     Sylvie      Cruz  \n",
      "1                                        Greece 2000     Sylvie      Cruz  \n",
      "2                                          Kilometer     Sylvie      Cruz  \n",
      "3  Catch You Baby (Steve Pitron & Max Sanna Radio...     Sylvie      Cruz  \n"
     ]
    }
   ],
   "source": [
    "# Give me only the following: name of artist, song (sorted by itemInSession) \n",
    "#and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "\n",
    "query = \"SELECT user_id, session_id, item_in_session, artist_name, song,  first_name, last_name  \\\n",
    "        FROM user_songs \\\n",
    "        WHERE session_id=182 \\\n",
    "        AND user_id = 10\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "df = pd.DataFrame(rows, columns=['User ID', 'Session ID', 'Item in Session', 'Artist Name', 'Song', 'First Name' , 'Last Name'])\n",
    "print(df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Created a table with the columns First Name, Last Name, Song Length, User ID because Sparkify wanted a list of their customers who listened to 'All Hands Against His Own'. I added User ID to be able to list all the customers who listened to the song, not just one customer.\n",
    "\n",
    "-Chose song name and user ID as the primary key to be able to get a list of all the customers who listened to the song. If I put the song name only as the primary key this would result in printing just one customer and not all the customers because the primary key has to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CREATING TABLE users\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS users \"\n",
    "query = query + \"( song text, user_id int , first_name text, last_name text, PRIMARY KEY(song, user_id))\"\n",
    "\n",
    "\n",
    "try:\n",
    "    session.execute (query)\n",
    "except Exception as e:\n",
    "    print (e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting up csv file\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) \n",
    "    \n",
    "    for line in csvreader:\n",
    "#Assign the INSERT statements \n",
    "        query = \"INSERT INTO users (song, user_id, first_name, last_name)\"\n",
    "    \n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        \n",
    "        #Assigning which column element should be assigned for each column in the INSERT statement.\n",
    "        session.execute(query, (  line[9], int(line[10]), line[1],  line[4]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-This query is just getting the data Sparkify wanted and listing them based on the User ID and Song Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   First Name Last Name                       Song  User ID\n",
      "0  Jacqueline     Lynch  All Hands Against His Own       29\n",
      "1       Tegan    Levine  All Hands Against His Own       80\n",
      "2        Sara   Johnson  All Hands Against His Own       95\n"
     ]
    }
   ],
   "source": [
    "#Every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n",
    "query = \"SELECT first_name, last_name, song, user_id \\\n",
    "        FROM users \\\n",
    "        WHERE song = 'All Hands Against His Own'\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "df = pd.DataFrame(rows, columns=['First Name', 'Last Name', 'Song', 'User ID'])\n",
    "\n",
    "print (df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"drop table artist_songs_length\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"drop table user_songs\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"drop table users\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print (e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing the session and cluster connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
